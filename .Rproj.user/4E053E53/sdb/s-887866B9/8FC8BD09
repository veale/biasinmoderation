{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Automated content moderation code\"\noutput:\n  github_document:\n    toc: true\n    toc_depth: 2\n---\n\nImport a load of stuff\n\n```{r, message = FALSE}\nrequire(irr)\nrequire(boot)\nrequire(tidyverse)\nrequire(pander)\n```\n\n## Toxicity\n\n```{r, message = FALSE}\ntox <- read_tsv(\"dat/toxicity_annotated_comments.tsv\")\ntox.dem <- read_tsv(\"dat/toxicity_worker_demographics.tsv\")\ntox.ann <- read_tsv(\"dat/toxicity_annotations.tsv\")\nagg <- read_tsv(\"dat/aggression_annotated_comments.tsv\")\nagg.dem <- read_tsv(\"dat/aggression_worker_demographics.tsv\")\nagg.ann <- read_tsv(\"dat/aggression_annotations.tsv\")\n\n```\n \n```{r}\n# Join data frames together\ntox.ann %>% left_join(tox.dem) -> tox.long\n```\n## Distribution of average toxicity per worker.\nWe might want to know what the average worker's toxicity score is.\n\n\n```{r}\ntox.long %>% group_by(worker_id, gender, age_group, education, english_first_language) %>% filter(gender %in% c(\"male\", \"female\", NA)) %>% summarise(mean.toxicityscore = mean(toxicity_score)) -> tox.workermeans\n\n\nggplot(tox.workermeans) + stat_density(aes(mean.toxicityscore)) + ggtitle(\"Distribution of mean toxicity score\") + theme_minimal()\n```\n\n```{r}\nggplot(tox.workermeans) + \n  geom_violin(aes(y = mean.toxicityscore, \n                  fill = gender, \n                  x = gender)) + \n  ggtitle(\"Distribution of mean toxicity score by gender\") + \n  theme_minimal()\n```\n\n```{r}\nggplot(tox.workermeans) + \n  geom_violin(aes(mean.toxicityscore, \n                  fill = age_group, \n                  x = age_group)) + \n  ggtitle(\"Distribution of mean toxicity score by age\") + \n  theme_minimal()\n```\n\n```{r}\nggplot(tox.workermeans) + \n  geom_violin(aes(mean.toxicityscore, \n                  fill = education, \n                  x = education)) + \n  ggtitle(\"Distribution of mean toxicity score by education\") + \n  theme_minimal()\n```\n\n```{r}\n  ggplot(tox.workermeans) + \n  geom_violin(aes(mean.toxicityscore, \n                  fill = factor(english_first_language), \n                  x = factor(english_first_language))) + \n  ggtitle(\"Distribution of mean toxicity score by first language\") + \n  theme_minimal()\n```\n\n\n### Can we predict who will have a higher mean toxicity score?\n\nDo this over the data with NA's subsetted out.\n```{r}\nlm(formula = mean.toxicityscore ~ gender + age_group + education + english_first_language,\n   data = tox.workermeans %>% na.omit) %>% \n  summary %>% \n  pander(add.significance.stars = T)\n```\n\n##  Getting aggressive\n\n```{r}\n# Join data frames together\nagg.ann %>% left_join(agg.dem) -> agg.long\n```\n## Distribution of average aggression per worker.\nWe might want to know what the average worker's aggression score is.\n\n\n```{r}\nagg.long %>% \n  group_by(worker_id, gender, age_group, education, english_first_language) %>% \n  filter(gender %in% c(\"male\", \"female\", NA)) %>% \n  summarise(mean.aggressionscore = mean(aggression_score)) -> agg.workermeans\n\n\nggplot(agg.workermeans) + \n  stat_density(aes(mean.aggressionscore)) + \n  ggtitle(\"Distribution of mean aggression score\") + \n  theme_minimal()\n```\n\n```{r}\nggplot(agg.workermeans) + \n  geom_violin(aes(y = mean.aggressionscore, \n                  fill = gender, \n                  x = gender)) + \n  ggtitle(\"Distribution of mean aggression score by gender\") + \n  theme_minimal()\n```\n\n```{r}\nggplot(agg.workermeans) + \n  geom_violin(aes(mean.aggressionscore, \n                  fill = age_group, \n                  x = age_group)) + \n  ggtitle(\"Distribution of mean aggression score by age\") + \n  theme_minimal()\n```\n\n```{r}\nggplot(agg.workermeans) +\n  geom_violin(aes(mean.aggressionscore, \n                  fill = education, \n                  x = education)) + \n  ggtitle(\"Distribution of mean aggression score by education\") +\n  theme_minimal()\n```\n\n```{r}\n  ggplot(agg.workermeans) + \n  geom_violin(aes(mean.aggressionscore, \n                  fill = factor(english_first_language), \n                  x = factor(english_first_language))) + \n  ggtitle(\"Distribution of mean aggression score by first language\") + \n  theme_minimal()\n```\n\n\n### Can we predict who will have a higher mean aggression score?\n\nDo this over the data with NA's subsetted out.\n```{r pander}\nlm(formula = mean.aggressionscore ~ gender + age_group + education + english_first_language,\n   data = agg.workermeans %>% na.omit) %>% \n  summary %>% \n  pander(add.significance.stars = T)\n```\n\n<!-- Make dissent metric per comment -->\n<!-- ```{r} -->\n<!-- tox.long %>% filter(!is.na(gender)) %>%  -->\n<!--   group_by(rev_id, gender) %>%  -->\n<!--   filter(n() > 1) %>% -->\n<!--   mutate(mean.tox = round(mean(toxicity)),  -->\n<!--          dissenter = ifelse(toxicity != mean.tox, 1, 0)) %>% -->\n<!--   summarise(dissent = sum(dissenter)/n()) -> tox.dissent -->\n<!-- ``` -->\n\n\n<!-- Sum dissent metric per comment -->\n<!-- ```{r} -->\n<!-- tox.dissent %>% filter(gender == \"female\")  -> tox.dissent.f -->\n<!-- tox.dissent %>% filter(gender == \"male\")  -> tox.dissent.m -->\n<!-- ``` -->\n\n\n\n",
    "created" : 1493317453598.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1592258290",
    "id" : "8FC8BD09",
    "lastKnownWriteTime" : 1493376897,
    "last_content_update" : 1493376897716,
    "path" : "~/Dropbox (Personal)/Make/Program/CSCW Automated Moderation/automatedmoderationnotebook.Rmd",
    "project_path" : "automatedmoderationnotebook.Rmd",
    "properties" : {
        "chunk_output_type" : "inline",
        "tempName" : "Untitled1"
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}